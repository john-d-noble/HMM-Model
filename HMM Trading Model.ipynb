{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c1849cf-3dbe-4306-a0c8-75738971ea2f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'SectorPerformances' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 10\u001b[0m\n\u001b[1;32m      7\u001b[0m base_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://paper-api.alpaca.markets\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# Get a reference to a a rest object\u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m api \u001b[38;5;241m=\u001b[39m \u001b[43malpacaapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREST\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_secret\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Get a list of all orders.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m open_orders_list \u001b[38;5;241m=\u001b[39m api\u001b[38;5;241m.\u001b[39mlist_orders(status\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mopen\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/finance_env/lib/python3.10/site-packages/alpaca_trade_api/rest.py:78\u001b[0m, in \u001b[0;36mREST.__init__\u001b[0;34m(self, key_id, secret_key, base_url, api_version, oauth)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_codes \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mint\u001b[39m(o)\u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39menviron\u001b[38;5;241m.\u001b[39mget(\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAPCA_RETRY_CODES\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m429,504\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolygon \u001b[38;5;241m=\u001b[39m polygon\u001b[38;5;241m.\u001b[39mREST(\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key_id, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstaging\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_base_url)\n\u001b[0;32m---> 78\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha_vantage \u001b[38;5;241m=\u001b[39m \u001b[43malpha_vantage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mREST\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_key_id\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/finance_env/lib/python3.10/site-packages/alpaca_trade_api/alpha_vantage/rest.py:14\u001b[0m, in \u001b[0;36mREST.__init__\u001b[0;34m(self, api_key)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_session \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mSession()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeseries \u001b[38;5;241m=\u001b[39m TimeSeries(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_key)\n\u001b[0;32m---> 14\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sectorperformance \u001b[38;5;241m=\u001b[39m \u001b[43mSectorPerformances\u001b[49m(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_key)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_techindicators \u001b[38;5;241m=\u001b[39m TechIndicators(key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_api_key)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'SectorPerformances' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a11e677-6460-4845-9251-d9638a75442b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/johnnoble/anaconda3/envs/finance_env/lib/python3.10/site-packages/requests/__init__.py:86: RequestsDependencyWarning: Unable to find acceptable character detection dependency (chardet or charset_normalizer).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-05 12:08:56,976 - INFO - Starting HMM trading strategy execution...\n",
      "2025-06-05 12:08:56,977 - INFO - Configuration validated successfully.\n",
      "2025-06-05 12:08:56,979 - INFO - Fetching data for tickers: ['NVDA', 'MSTR', 'PLTR', 'TSLA'] from 2020-06-06 to 2025-06-04\n",
      "2025-06-05 12:08:56,980 - INFO - Attempting to fetch data for NVDA from 2020-06-06 to 2025-06-04...\n",
      "2025-06-05 12:08:57,478 - INFO - Successfully fetched data for NVDA. Rows: 1254\n",
      "2025-06-05 12:08:57,479 - INFO - Attempting to fetch data for MSTR from 2020-06-06 to 2025-06-04...\n",
      "2025-06-05 12:08:57,732 - INFO - Successfully fetched data for MSTR. Rows: 1254\n",
      "2025-06-05 12:08:57,733 - INFO - Attempting to fetch data for PLTR from 2020-06-06 to 2025-06-04...\n",
      "2025-06-05 12:08:58,084 - INFO - Successfully fetched data for PLTR. Rows: 1174\n",
      "2025-06-05 12:08:58,085 - INFO - Attempting to fetch data for TSLA from 2020-06-06 to 2025-06-04...\n",
      "2025-06-05 12:08:58,293 - INFO - Successfully fetched data for TSLA. Rows: 1254\n",
      "2025-06-05 12:08:58,307 - INFO - Features shape for NVDA: (1234, 4). First 5 rows of features:\\n[[ 3.30328023e-03  3.92090420e-01  6.92003809e+01  1.32665595e-01]\n",
      " [ 3.48720986e-02  3.98360188e-01  7.16000865e+01  2.14645053e-02]\n",
      " [ 2.86804371e-02  3.92486925e-01  7.53783834e+01  3.53146547e-01]\n",
      " [-2.83074223e-03  3.05567781e-01  7.40711580e+01  6.32496745e-03]\n",
      " [-4.07472798e-02  3.51413154e-01  5.97621969e+01 -8.15791800e-02]]\n",
      "2025-06-05 12:08:58,308 - INFO - DataFrame shape after feature prep for NVDA: (1234, 9)\n",
      "2025-06-05 12:08:58,310 - INFO - Loaded HMM model for NVDA from hmm_models/NVDA_hmm_model.pkl\n",
      "2025-06-05 12:08:58,314 - INFO - [Date] ENTERING generate_signals. Initial df rows: 1234\n",
      "2025-06-05 12:08:58,315 - INFO - [Date] Initial DataFrame 'df' index for Date is unique. Proceeding.\n",
      "2025-06-05 12:08:58,318 - INFO - [Date] Added 'State' column. df_temp rows: 1234\n",
      "2025-06-05 12:08:58,326 - INFO - [Date] Signal map: {np.int64(1): 1}, Last 5 signals:\\nDate\n",
      "2025-05-28    1\n",
      "2025-05-29    1\n",
      "2025-05-30    1\n",
      "2025-06-02    1\n",
      "2025-06-03    1\n",
      "Name: Signal, dtype: int64\n",
      "2025-06-05 12:08:58,335 - INFO - [Date] DEBUG: Calculated 'Position'.\n",
      "2025-06-05 12:08:58,341 - INFO - [Date] DEBUG: Calculating long SL.\n",
      "2025-06-05 12:08:58,343 - INFO - [Date] DEBUG: s1_long defined.\n",
      "2025-06-05 12:08:58,345 - INFO - [Date] DEBUG: op_low type: <class 'pandas.core.frame.DataFrame'>, ndim: 2, shape: (1234, 1)\n",
      "2025-06-05 12:08:58,346 - INFO - [Date] DEBUG: op_sl_long type: <class 'pandas.core.series.Series'>, ndim: 1, shape: (1234,)\n",
      "2025-06-05 12:08:58,347 - INFO - [Date] DEBUG: op_low_vals ndim: 2, shape: (1234, 1)\n",
      "2025-06-05 12:08:58,348 - INFO - [Date] DEBUG: op_sl_long_vals ndim: 1, shape: (1234,)\n",
      "2025-06-05 12:08:58,349 - INFO - [Date] DEBUG: SQUEEZED op_low_vals ndim: 1, shape: (1234,)\n",
      "2025-06-05 12:08:58,351 - INFO - [Date] DEBUG: SQUEEZED op_sl_long_vals ndim: 1, shape: (1234,)\n",
      "2025-06-05 12:08:58,352 - INFO - [Date] DEBUG: Attempting comparison for s2_long using .values: op_low_vals <= op_sl_long_vals\n",
      "2025-06-05 12:08:58,353 - INFO - [Date] DEBUG: s2_long defined via .values comparison. Shape of result: (1234,)\n",
      "2025-06-05 12:08:58,354 - INFO - [Date] DEBUG: Aligning s1_long and s2_long for '&'. Pre-align: s1_long.index.equals(s2_long.index): True\n",
      "2025-06-05 12:08:58,355 - INFO - [Date] DEBUG: s1_long & s2_long aligned. Post-align: s1_aligned.equals(s2_aligned): True\n",
      "2025-06-05 12:08:58,357 - INFO - [Date] DEBUG: Long SL condition applied.\n",
      "2025-06-05 12:08:58,358 - INFO - [Date] DEBUG: Calculating short SL.\n",
      "2025-06-05 12:08:58,360 - INFO - [Date] DEBUG: s1_short defined.\n",
      "2025-06-05 12:08:58,363 - INFO - [Date] DEBUG: op_high type: <class 'pandas.core.frame.DataFrame'>, ndim: 2, shape: (1234, 1)\n",
      "2025-06-05 12:08:58,365 - INFO - [Date] DEBUG: op_sl_short type: <class 'pandas.core.series.Series'>, ndim: 1, shape: (1234,)\n",
      "2025-06-05 12:08:58,366 - INFO - [Date] DEBUG: op_high_vals ndim: 2, shape: (1234, 1)\n",
      "2025-06-05 12:08:58,367 - INFO - [Date] DEBUG: op_sl_short_vals ndim: 1, shape: (1234,)\n",
      "2025-06-05 12:08:58,368 - INFO - [Date] DEBUG: SQUEEZED op_high_vals ndim: 1, shape: (1234,)\n",
      "2025-06-05 12:08:58,369 - INFO - [Date] DEBUG: SQUEEZED op_sl_short_vals ndim: 1, shape: (1234,)\n",
      "2025-06-05 12:08:58,370 - INFO - [Date] DEBUG: Attempting comparison for s2_short using .values: op_high_vals >= op_sl_short_vals\n",
      "2025-06-05 12:08:58,371 - INFO - [Date] DEBUG: s2_short defined via .values comparison. Shape of result: (1234,)\n",
      "2025-06-05 12:08:58,372 - INFO - [Date] DEBUG: Aligning s1_short and s2_short for '&'. Pre-align: s1_short.index.equals(s2_short.index): True\n",
      "2025-06-05 12:08:58,374 - INFO - [Date] DEBUG: s1_short & s2_short aligned. Post-align: s1_aligned.equals(s2_aligned): True\n",
      "2025-06-05 12:08:58,376 - INFO - [Date] DEBUG: Short SL condition applied.\n",
      "2025-06-05 12:08:58,380 - INFO - [Date] DEBUG: Applied 'Daily_Exit_Condition' to 'Final_Position'.\n",
      "2025-06-05 12:08:58,383 - INFO - [Date] Signal generation completed. df_temp rows: 1234\n",
      "2025-06-05 12:08:58,385 - WARNING - Stagnant signals for NVDA: Signals unchanged for the last 5 trading days. Consider model review.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/hl_dymcd4sd7l6g5mb473brw0000gn/T/ipykernel_36031/1072186020.py:409: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['Final_Position'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-05 12:08:59,554 - INFO - Alert sent: WARNING: Stagnant Signals: NVDA\n",
      "2025-06-05 12:08:59,569 - INFO - Features shape for MSTR: (1234, 4). First 5 rows of features:\\n[[-1.38622431e-02  3.25639304e-01  4.10125501e+01 -3.92768080e-01]\n",
      " [ 1.10081587e-03  3.25870396e-01  4.18105372e+01  9.17864476e-01]\n",
      " [-7.18990761e-03  3.23668349e-01  4.47776239e+01 -5.77087794e-01]\n",
      " [ 2.47076148e-03  2.62875794e-01  4.86074507e+01  2.10126582e-01]\n",
      " [-1.58931943e-02  2.68046926e-01  4.28361187e+01  4.24686192e-01]]\n",
      "2025-06-05 12:08:59,570 - INFO - DataFrame shape after feature prep for MSTR: (1234, 9)\n",
      "2025-06-05 12:08:59,571 - INFO - HMM model for MSTR not found. Training new model.\n",
      "2025-06-05 12:08:59,572 - INFO - Optimizing HMM for states from 2 to 5...\n",
      "2025-06-05 12:08:59,723 - INFO - HMM with 2 states: Log-Likelihood = -4626.07, BIC = 9387.38\n",
      "2025-06-05 12:08:59,746 - INFO - HMM with 3 states: Log-Likelihood = -4009.33, BIC = 8246.43\n",
      "2025-06-05 12:08:59,788 - INFO - HMM with 4 states: Log-Likelihood = -3512.47, BIC = 7359.49\n",
      "2025-06-05 12:08:59,810 - INFO - HMM with 5 states: Log-Likelihood = -4059.97, BIC = 8575.49\n",
      "2025-06-05 12:08:59,811 - INFO - Optimal HMM chosen with 4 states (BIC: 7359.49).\n",
      "2025-06-05 12:08:59,813 - INFO - Saved new HMM model for MSTR to hmm_models/MSTR_hmm_model.pkl\n",
      "2025-06-05 12:08:59,816 - INFO - [Date] ENTERING generate_signals. Initial df rows: 1234\n",
      "2025-06-05 12:08:59,817 - INFO - [Date] Initial DataFrame 'df' index for Date is unique. Proceeding.\n",
      "2025-06-05 12:08:59,821 - INFO - [Date] Added 'State' column. df_temp rows: 1234\n",
      "2025-06-05 12:08:59,830 - INFO - [Date] Signal map: {np.int64(1): 1}, Last 5 signals:\\nDate\n",
      "2025-05-28    1\n",
      "2025-05-29    1\n",
      "2025-05-30    1\n",
      "2025-06-02    1\n",
      "2025-06-03    1\n",
      "Name: Signal, dtype: int64\n",
      "2025-06-05 12:08:59,839 - INFO - [Date] DEBUG: Calculated 'Position'.\n",
      "2025-06-05 12:08:59,845 - INFO - [Date] DEBUG: Calculating long SL.\n",
      "2025-06-05 12:08:59,848 - INFO - [Date] DEBUG: s1_long defined.\n",
      "2025-06-05 12:08:59,851 - INFO - [Date] DEBUG: op_low type: <class 'pandas.core.frame.DataFrame'>, ndim: 2, shape: (1234, 1)\n",
      "2025-06-05 12:08:59,852 - INFO - [Date] DEBUG: op_sl_long type: <class 'pandas.core.series.Series'>, ndim: 1, shape: (1234,)\n",
      "2025-06-05 12:08:59,853 - INFO - [Date] DEBUG: op_low_vals ndim: 2, shape: (1234, 1)\n",
      "2025-06-05 12:08:59,854 - INFO - [Date] DEBUG: op_sl_long_vals ndim: 1, shape: (1234,)\n",
      "2025-06-05 12:08:59,855 - INFO - [Date] DEBUG: SQUEEZED op_low_vals ndim: 1, shape: (1234,)\n",
      "2025-06-05 12:08:59,856 - INFO - [Date] DEBUG: SQUEEZED op_sl_long_vals ndim: 1, shape: (1234,)\n",
      "2025-06-05 12:08:59,857 - INFO - [Date] DEBUG: Attempting comparison for s2_long using .values: op_low_vals <= op_sl_long_vals\n",
      "2025-06-05 12:08:59,858 - INFO - [Date] DEBUG: s2_long defined via .values comparison. Shape of result: (1234,)\n",
      "2025-06-05 12:08:59,859 - INFO - [Date] DEBUG: Aligning s1_long and s2_long for '&'. Pre-align: s1_long.index.equals(s2_long.index): True\n",
      "2025-06-05 12:08:59,860 - INFO - [Date] DEBUG: s1_long & s2_long aligned. Post-align: s1_aligned.equals(s2_aligned): True\n",
      "2025-06-05 12:08:59,862 - INFO - [Date] DEBUG: Long SL condition applied.\n",
      "2025-06-05 12:08:59,863 - INFO - [Date] DEBUG: Calculating short SL.\n",
      "2025-06-05 12:08:59,866 - INFO - [Date] DEBUG: s1_short defined.\n",
      "2025-06-05 12:08:59,869 - INFO - [Date] DEBUG: op_high type: <class 'pandas.core.frame.DataFrame'>, ndim: 2, shape: (1234, 1)\n",
      "2025-06-05 12:08:59,870 - INFO - [Date] DEBUG: op_sl_short type: <class 'pandas.core.series.Series'>, ndim: 1, shape: (1234,)\n",
      "2025-06-05 12:08:59,871 - INFO - [Date] DEBUG: op_high_vals ndim: 2, shape: (1234, 1)\n",
      "2025-06-05 12:08:59,872 - INFO - [Date] DEBUG: op_sl_short_vals ndim: 1, shape: (1234,)\n",
      "2025-06-05 12:08:59,873 - INFO - [Date] DEBUG: SQUEEZED op_high_vals ndim: 1, shape: (1234,)\n",
      "2025-06-05 12:08:59,874 - INFO - [Date] DEBUG: SQUEEZED op_sl_short_vals ndim: 1, shape: (1234,)\n",
      "2025-06-05 12:08:59,875 - INFO - [Date] DEBUG: Attempting comparison for s2_short using .values: op_high_vals >= op_sl_short_vals\n",
      "2025-06-05 12:08:59,876 - INFO - [Date] DEBUG: s2_short defined via .values comparison. Shape of result: (1234,)\n",
      "2025-06-05 12:08:59,877 - INFO - [Date] DEBUG: Aligning s1_short and s2_short for '&'. Pre-align: s1_short.index.equals(s2_short.index): True\n",
      "2025-06-05 12:08:59,878 - INFO - [Date] DEBUG: s1_short & s2_short aligned. Post-align: s1_aligned.equals(s2_aligned): True\n",
      "2025-06-05 12:08:59,881 - INFO - [Date] DEBUG: Short SL condition applied.\n",
      "2025-06-05 12:08:59,885 - INFO - [Date] DEBUG: Applied 'Daily_Exit_Condition' to 'Final_Position'.\n",
      "2025-06-05 12:08:59,888 - INFO - [Date] Signal generation completed. df_temp rows: 1234\n",
      "2025-06-05 12:08:59,890 - WARNING - Stagnant signals for MSTR: Signals unchanged for the last 5 trading days. Consider model review.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/hl_dymcd4sd7l6g5mb473brw0000gn/T/ipykernel_36031/1072186020.py:409: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['Final_Position'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-05 12:09:00,734 - INFO - Alert sent: WARNING: Stagnant Signals: MSTR\n",
      "2025-06-05 12:09:00,746 - INFO - Features shape for PLTR: (1154, 4). First 5 rows of features:\\n[[-9.13236799e-03  6.56173591e-01  6.01918509e+01 -4.23760473e-01]\n",
      " [-9.21662470e-03  6.57592400e-01  5.94786746e+01 -3.36956276e-01]\n",
      " [-5.76744080e-02  6.86794544e-01  5.25104575e+01 -3.94917064e-02]\n",
      " [ 4.04738246e-02  6.91147342e-01  6.12159286e+01 -4.07383725e-01]\n",
      " [-3.79506281e-03  6.09139772e-01  6.23931600e+01  8.54184864e-01]]\n",
      "2025-06-05 12:09:00,747 - INFO - DataFrame shape after feature prep for PLTR: (1154, 9)\n",
      "2025-06-05 12:09:00,749 - INFO - HMM model for PLTR not found. Training new model.\n",
      "2025-06-05 12:09:00,751 - INFO - Optimizing HMM for states from 2 to 5...\n",
      "2025-06-05 12:09:00,760 - INFO - HMM with 2 states: Log-Likelihood = -3284.28, BIC = 6702.54\n",
      "2025-06-05 12:09:00,781 - INFO - HMM with 3 states: Log-Likelihood = -3029.43, BIC = 6284.49\n",
      "2025-06-05 12:09:00,951 - INFO - HMM with 4 states: Log-Likelihood = -2300.15, BIC = 4931.70\n",
      "2025-06-05 12:09:01,008 - INFO - HMM with 5 states: Log-Likelihood = -2615.05, BIC = 5681.36\n",
      "2025-06-05 12:09:01,009 - INFO - Optimal HMM chosen with 4 states (BIC: 4931.70).\n",
      "2025-06-05 12:09:01,011 - INFO - Saved new HMM model for PLTR to hmm_models/PLTR_hmm_model.pkl\n",
      "2025-06-05 12:09:01,015 - INFO - [Date] ENTERING generate_signals. Initial df rows: 1154\n",
      "2025-06-05 12:09:01,016 - INFO - [Date] Initial DataFrame 'df' index for Date is unique. Proceeding.\n",
      "2025-06-05 12:09:01,019 - INFO - [Date] Added 'State' column. df_temp rows: 1154\n",
      "2025-06-05 12:09:01,029 - INFO - [Date] Signal map: {np.int64(0): 1}, Last 5 signals:\\nDate\n",
      "2025-05-28    1\n",
      "2025-05-29    1\n",
      "2025-05-30    1\n",
      "2025-06-02    1\n",
      "2025-06-03    1\n",
      "Name: Signal, dtype: int64\n",
      "2025-06-05 12:09:01,040 - INFO - [Date] DEBUG: Calculated 'Position'.\n",
      "2025-06-05 12:09:01,049 - INFO - [Date] DEBUG: Calculating long SL.\n",
      "2025-06-05 12:09:01,053 - INFO - [Date] DEBUG: s1_long defined.\n",
      "2025-06-05 12:09:01,055 - INFO - [Date] DEBUG: op_low type: <class 'pandas.core.frame.DataFrame'>, ndim: 2, shape: (1154, 1)\n",
      "2025-06-05 12:09:01,056 - INFO - [Date] DEBUG: op_sl_long type: <class 'pandas.core.series.Series'>, ndim: 1, shape: (1154,)\n",
      "2025-06-05 12:09:01,057 - INFO - [Date] DEBUG: op_low_vals ndim: 2, shape: (1154, 1)\n",
      "2025-06-05 12:09:01,058 - INFO - [Date] DEBUG: op_sl_long_vals ndim: 1, shape: (1154,)\n",
      "2025-06-05 12:09:01,059 - INFO - [Date] DEBUG: SQUEEZED op_low_vals ndim: 1, shape: (1154,)\n",
      "2025-06-05 12:09:01,060 - INFO - [Date] DEBUG: SQUEEZED op_sl_long_vals ndim: 1, shape: (1154,)\n",
      "2025-06-05 12:09:01,061 - INFO - [Date] DEBUG: Attempting comparison for s2_long using .values: op_low_vals <= op_sl_long_vals\n",
      "2025-06-05 12:09:01,063 - INFO - [Date] DEBUG: s2_long defined via .values comparison. Shape of result: (1154,)\n",
      "2025-06-05 12:09:01,064 - INFO - [Date] DEBUG: Aligning s1_long and s2_long for '&'. Pre-align: s1_long.index.equals(s2_long.index): True\n",
      "2025-06-05 12:09:01,066 - INFO - [Date] DEBUG: s1_long & s2_long aligned. Post-align: s1_aligned.equals(s2_aligned): True\n",
      "2025-06-05 12:09:01,068 - INFO - [Date] DEBUG: Long SL condition applied.\n",
      "2025-06-05 12:09:01,069 - INFO - [Date] DEBUG: Calculating short SL.\n",
      "2025-06-05 12:09:01,071 - INFO - [Date] DEBUG: s1_short defined.\n",
      "2025-06-05 12:09:01,074 - INFO - [Date] DEBUG: op_high type: <class 'pandas.core.frame.DataFrame'>, ndim: 2, shape: (1154, 1)\n",
      "2025-06-05 12:09:01,075 - INFO - [Date] DEBUG: op_sl_short type: <class 'pandas.core.series.Series'>, ndim: 1, shape: (1154,)\n",
      "2025-06-05 12:09:01,076 - INFO - [Date] DEBUG: op_high_vals ndim: 2, shape: (1154, 1)\n",
      "2025-06-05 12:09:01,077 - INFO - [Date] DEBUG: op_sl_short_vals ndim: 1, shape: (1154,)\n",
      "2025-06-05 12:09:01,078 - INFO - [Date] DEBUG: SQUEEZED op_high_vals ndim: 1, shape: (1154,)\n",
      "2025-06-05 12:09:01,079 - INFO - [Date] DEBUG: SQUEEZED op_sl_short_vals ndim: 1, shape: (1154,)\n",
      "2025-06-05 12:09:01,080 - INFO - [Date] DEBUG: Attempting comparison for s2_short using .values: op_high_vals >= op_sl_short_vals\n",
      "2025-06-05 12:09:01,082 - INFO - [Date] DEBUG: s2_short defined via .values comparison. Shape of result: (1154,)\n",
      "2025-06-05 12:09:01,083 - INFO - [Date] DEBUG: Aligning s1_short and s2_short for '&'. Pre-align: s1_short.index.equals(s2_short.index): True\n",
      "2025-06-05 12:09:01,085 - INFO - [Date] DEBUG: s1_short & s2_short aligned. Post-align: s1_aligned.equals(s2_aligned): True\n",
      "2025-06-05 12:09:01,087 - INFO - [Date] DEBUG: Short SL condition applied.\n",
      "2025-06-05 12:09:01,093 - INFO - [Date] DEBUG: Applied 'Daily_Exit_Condition' to 'Final_Position'.\n",
      "2025-06-05 12:09:01,095 - INFO - [Date] Signal generation completed. df_temp rows: 1154\n",
      "2025-06-05 12:09:01,098 - WARNING - Stagnant signals for PLTR: Signals unchanged for the last 5 trading days. Consider model review.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/hl_dymcd4sd7l6g5mb473brw0000gn/T/ipykernel_36031/1072186020.py:409: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['Final_Position'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-05 12:09:02,115 - INFO - Alert sent: WARNING: Stagnant Signals: PLTR\n",
      "2025-06-05 12:09:02,131 - INFO - Features shape for TSLA: (1234, 4). First 5 rows of features:\\n[[ 1.33276885e-02  7.69141195e-01  8.63169146e+01  4.47158226e-02]\n",
      " [-1.72535003e-02  7.73482861e-01  8.24917137e+01 -2.40971256e-01]\n",
      " [ 2.07924565e-02  7.28377596e-01  8.29717942e+01 -2.81626848e-01]\n",
      " [ 1.07847765e-01  7.51214421e-01  8.67791265e+01  9.91670649e-01]\n",
      " [-3.08095851e-02  7.43002985e-01  8.22178320e+01  6.70497395e-01]]\n",
      "2025-06-05 12:09:02,132 - INFO - DataFrame shape after feature prep for TSLA: (1234, 9)\n",
      "2025-06-05 12:09:02,135 - INFO - Loaded HMM model for TSLA from hmm_models/TSLA_hmm_model.pkl\n",
      "2025-06-05 12:09:02,138 - INFO - [Date] ENTERING generate_signals. Initial df rows: 1234\n",
      "2025-06-05 12:09:02,139 - INFO - [Date] Initial DataFrame 'df' index for Date is unique. Proceeding.\n",
      "2025-06-05 12:09:02,142 - INFO - [Date] Added 'State' column. df_temp rows: 1234\n",
      "2025-06-05 12:09:02,154 - INFO - [Date] Signal map: {np.int64(1): 1}, Last 5 signals:\\nDate\n",
      "2025-05-28    1\n",
      "2025-05-29    1\n",
      "2025-05-30    1\n",
      "2025-06-02    1\n",
      "2025-06-03    1\n",
      "Name: Signal, dtype: int64\n",
      "2025-06-05 12:09:02,167 - INFO - [Date] DEBUG: Calculated 'Position'.\n",
      "2025-06-05 12:09:02,177 - INFO - [Date] DEBUG: Calculating long SL.\n",
      "2025-06-05 12:09:02,180 - INFO - [Date] DEBUG: s1_long defined.\n",
      "2025-06-05 12:09:02,184 - INFO - [Date] DEBUG: op_low type: <class 'pandas.core.frame.DataFrame'>, ndim: 2, shape: (1234, 1)\n",
      "2025-06-05 12:09:02,185 - INFO - [Date] DEBUG: op_sl_long type: <class 'pandas.core.series.Series'>, ndim: 1, shape: (1234,)\n",
      "2025-06-05 12:09:02,186 - INFO - [Date] DEBUG: op_low_vals ndim: 2, shape: (1234, 1)\n",
      "2025-06-05 12:09:02,188 - INFO - [Date] DEBUG: op_sl_long_vals ndim: 1, shape: (1234,)\n",
      "2025-06-05 12:09:02,189 - INFO - [Date] DEBUG: SQUEEZED op_low_vals ndim: 1, shape: (1234,)\n",
      "2025-06-05 12:09:02,190 - INFO - [Date] DEBUG: SQUEEZED op_sl_long_vals ndim: 1, shape: (1234,)\n",
      "2025-06-05 12:09:02,191 - INFO - [Date] DEBUG: Attempting comparison for s2_long using .values: op_low_vals <= op_sl_long_vals\n",
      "2025-06-05 12:09:02,192 - INFO - [Date] DEBUG: s2_long defined via .values comparison. Shape of result: (1234,)\n",
      "2025-06-05 12:09:02,194 - INFO - [Date] DEBUG: Aligning s1_long and s2_long for '&'. Pre-align: s1_long.index.equals(s2_long.index): True\n",
      "2025-06-05 12:09:02,195 - INFO - [Date] DEBUG: s1_long & s2_long aligned. Post-align: s1_aligned.equals(s2_aligned): True\n",
      "2025-06-05 12:09:02,197 - INFO - [Date] DEBUG: Long SL condition applied.\n",
      "2025-06-05 12:09:02,198 - INFO - [Date] DEBUG: Calculating short SL.\n",
      "2025-06-05 12:09:02,202 - INFO - [Date] DEBUG: s1_short defined.\n",
      "2025-06-05 12:09:02,204 - INFO - [Date] DEBUG: op_high type: <class 'pandas.core.frame.DataFrame'>, ndim: 2, shape: (1234, 1)\n",
      "2025-06-05 12:09:02,206 - INFO - [Date] DEBUG: op_sl_short type: <class 'pandas.core.series.Series'>, ndim: 1, shape: (1234,)\n",
      "2025-06-05 12:09:02,207 - INFO - [Date] DEBUG: op_high_vals ndim: 2, shape: (1234, 1)\n",
      "2025-06-05 12:09:02,208 - INFO - [Date] DEBUG: op_sl_short_vals ndim: 1, shape: (1234,)\n",
      "2025-06-05 12:09:02,210 - INFO - [Date] DEBUG: SQUEEZED op_high_vals ndim: 1, shape: (1234,)\n",
      "2025-06-05 12:09:02,211 - INFO - [Date] DEBUG: SQUEEZED op_sl_short_vals ndim: 1, shape: (1234,)\n",
      "2025-06-05 12:09:02,212 - INFO - [Date] DEBUG: Attempting comparison for s2_short using .values: op_high_vals >= op_sl_short_vals\n",
      "2025-06-05 12:09:02,214 - INFO - [Date] DEBUG: s2_short defined via .values comparison. Shape of result: (1234,)\n",
      "2025-06-05 12:09:02,216 - INFO - [Date] DEBUG: Aligning s1_short and s2_short for '&'. Pre-align: s1_short.index.equals(s2_short.index): True\n",
      "2025-06-05 12:09:02,218 - INFO - [Date] DEBUG: s1_short & s2_short aligned. Post-align: s1_aligned.equals(s2_aligned): True\n",
      "2025-06-05 12:09:02,221 - INFO - [Date] DEBUG: Short SL condition applied.\n",
      "2025-06-05 12:09:02,226 - INFO - [Date] DEBUG: Applied 'Daily_Exit_Condition' to 'Final_Position'.\n",
      "2025-06-05 12:09:02,229 - INFO - [Date] Signal generation completed. df_temp rows: 1234\n",
      "2025-06-05 12:09:02,232 - WARNING - Stagnant signals for TSLA: Signals unchanged for the last 5 trading days. Consider model review.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/50/hl_dymcd4sd7l6g5mb473brw0000gn/T/ipykernel_36031/1072186020.py:409: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_temp['Final_Position'].fillna(0, inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-06-05 12:09:03,313 - INFO - Alert sent: WARNING: Stagnant Signals: TSLA\n",
      "2025-06-05 12:09:03,343 - INFO - Saved processed data for NVDA to data/NVDA_processed_data.csv\n",
      "2025-06-05 12:09:03,370 - INFO - Saved processed data for MSTR to data/MSTR_processed_data.csv\n",
      "2025-06-05 12:09:03,395 - INFO - Saved processed data for PLTR to data/PLTR_processed_data.csv\n",
      "2025-06-05 12:09:03,424 - INFO - Saved processed data for TSLA to data/TSLA_processed_data.csv\n",
      "2025-06-05 12:09:03,433 - WARNING - Market benchmark SPY not found in processed_data or 'Returns' column missing. Market returns set to 0.\n",
      "2025-06-05 12:09:03,475 - INFO - Backtest completed successfully.\n",
      "2025-06-05 12:09:03,478 - INFO - Calculated performance metrics: Sharpe=10.95, Max Drawdown=-0.36%\n",
      "2025-06-05 12:09:03,480 - INFO - FINAL PERFORMANCE: Sharpe Ratio: 10.95\n",
      "2025-06-05 12:09:03,481 - INFO - FINAL PERFORMANCE: Max Drawdown: -0.36%\n",
      "2025-06-05 12:09:03,483 - INFO - FINAL PERFORMANCE: Strategy Return: 466.75%\n",
      "2025-06-05 12:09:03,485 - INFO - FINAL PERFORMANCE: Market Return (Benchmark: SPY): 0.00%\n",
      "2025-06-05 12:09:04,381 - INFO - Alert sent: Daily Trading Report\n",
      "2025-06-05 12:09:04,383 - INFO - Initiating paper trading operations...\n",
      "2025-06-05 12:09:04,384 - ERROR - Paper trading failed: name 'SectorPerformances' is not defined\n",
      "2025-06-05 12:09:05,236 - INFO - Alert sent: CRITICAL: Paper Trading Failure\n",
      "2025-06-05 12:09:05,337 - ERROR - Failed to generate performance plot: name 'joined_tickers_str' is not defined\n",
      "2025-06-05 12:09:06,161 - INFO - Alert sent: ERROR: Plot Generation Failure\n",
      "2025-06-05 12:09:06,162 - INFO - HMM trading strategy execution finished.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1400x700 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging # Make sure logging is configured in your notebook\n",
    "from hmmlearn.hmm import GaussianHMM\n",
    "from sklearn.model_selection import train_test_split # Not directly used in final code, but often in ML. Kept for dependencies.\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "import smtplib\n",
    "from email.mime.text import MIMEText\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "import pickle\n",
    "from alpaca_trade_api.rest import REST\n",
    "import time\n",
    "import sys # For sys.exit()\n",
    "\n",
    "# -------------------------------------\\n\",\n",
    "# Configuration: Input Credentials\\n\",\n",
    "# -------------------------------------\\n\",\n",
    "CONFIG = {\n",
    "    'ALPHA_VANTAGE_API_KEY': '',  # Get from https://www.alphavantage.co\n",
    "    'ALPACA_API_KEY': '',              # Get from https://alpaca.markets (Paper Trading)\n",
    "    'ALPACA_SECRET_KEY': '',        # Get from https://alpaca.markets (Paper Trading)\n",
    "    'SMTP_EMAIL': '',                 # Gmail address for alerts\n",
    "    'SMTP_PASSWORD': '',                 # Gmail App Password (16 characters, no spaces)\n",
    "    'ALPACAY_BASE_URL': 'https://paper-api.alpaca.markets', # Use 'https://api.alpaca.markets' for live trading\n",
    "    'LOG_FILE': 'trading_log.txt',\n",
    "    'PERFORMANCE_PLOT_FILE': 'performance.png',\n",
    "    'HMM_MODEL_DIR': 'hmm_models', # Directory to store HMM models\n",
    "    'DATA_DIR': 'data', # Directory to store downloaded data\n",
    "    'DAILY_LOSS_THRESHOLD': -0.05, # -5% daily portfolio loss to halt\n",
    "    'STOP_LOSS_PERCENTAGE': 0.03, # 3% stop-loss from previous close\n",
    "    'POSITION_SIZE_MIN': 0.1, # Min 10% volatility-based position\n",
    "    'POSITION_SIZE_MAX': 0.2, # Max 20% volatility-based position\n",
    "    'MAX_PORTFOLIO_EXPOSURE': 0.5, # 50% max exposure\n",
    "    'HMM_MIN_STATES': 2, # Minimum number of states for HMM optimization\n",
    "    'HMM_MAX_STATES': 5, # Maximum number of states for HMM optimization\n",
    "    'DATA_LOOKBACK_YEARS': 5, # Years of historical data to fetch\n",
    "    'RETRY_ATTEMPTS': 5, # Retries for data fetching\n",
    "    'RETRY_DELAY_SECONDS': 10 # Delay between retries\n",
    "}\n",
    "\n",
    "# Ensure necessary directories exist\n",
    "os.makedirs(CONFIG['HMM_MODEL_DIR'], exist_ok=True)\n",
    "os.makedirs(CONFIG['DATA_DIR'], exist_ok=True)\n",
    "\n",
    "# -------------------------------------\\n\",\n",
    "# Logging Setup\\n\",\n",
    "# -------------------------------------\\n\",\n",
    "# Clear previous log content on each run for fresh logs, or append for continuous logging.\n",
    "# For a production system, you might want to rotate logs or append.\n",
    "# For this \\\"life or death\\\" scenario, let's keep it clean for daily review.\n",
    "if os.path.exists(CONFIG['LOG_FILE']):\n",
    "    with open(CONFIG['LOG_FILE'], 'w') as f:\n",
    "        f.truncate(0)\n",
    "\n",
    "logging.basicConfig(filename=CONFIG['LOG_FILE'], level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Also log to console for immediate feedback\n",
    "console_handler = logging.StreamHandler(sys.stdout)\n",
    "console_handler.setLevel(logging.INFO)\n",
    "formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
    "console_handler.setFormatter(formatter)\n",
    "logging.getLogger().addHandler(console_handler)\n",
    "\n",
    "\n",
    "# -------------------------------------\\n\",\n",
    "# Utility Functions\\n\",\n",
    "# -------------------------------------\\n\",\n",
    "def validate_config():\n",
    "    \"\"\"Ensure all required credentials and critical configurations are provided.\"\"\"\n",
    "    required_keys = ['ALPACA_API_KEY', 'ALPACA_SECRET_KEY', 'SMTP_EMAIL', 'SMTP_PASSWORD']\n",
    "    for key in required_keys:\n",
    "        if CONFIG[key] == f'YOUR_{key}' or not CONFIG[key] or (key == 'SMTP_PASSWORD' and len(CONFIG[key].replace(' ', '')) != 16):\n",
    "            raise ValueError(f\"Missing or invalid {key}. Update CONFIG dictionary. For SMTP_PASSWORD, ensure it's a 16-character Gmail App Password.\")\n",
    "    logging.info(\"Configuration validated successfully.\")\n",
    "\n",
    "def send_alert(subject, body):\n",
    "    \"\"\"Send email alert for failures and critical events.\"\"\"\n",
    "    try:\n",
    "        msg = MIMEText(body)\n",
    "        msg['Subject'] = subject\n",
    "        msg['From'] = CONFIG['SMTP_EMAIL']\n",
    "        msg['To'] = CONFIG['SMTP_EMAIL'] # Sending to self for alerts\n",
    "\n",
    "        with smtplib.SMTP('smtp.gmail.com', 587) as server:\n",
    "            server.starttls()\n",
    "            server.login(CONFIG['SMTP_EMAIL'], CONFIG['SMTP_PASSWORD'])\n",
    "            server.send_message(msg)\n",
    "        logging.info(f\"Alert sent: {subject}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to send alert: {e}. Check SMTP_EMAIL and SMTP_PASSWORD in CONFIG.\")\n",
    "\n",
    "# -------------------------------------\\n\",\n",
    "# Data Fetching\\n\",\n",
    "# -------------------------------------\\n\",\n",
    "def fetch_data(tickers, start_date, end_date):\n",
    "    \"\"\"Fetch OHLCV data from Yahoo Finance with retries.\"\"\"\n",
    "    data = {}\n",
    "    for ticker in tickers:\n",
    "        logging.info(f\"Attempting to fetch data for {ticker} from {start_date} to {end_date}...\")\n",
    "        for attempt in range(CONFIG['RETRY_ATTEMPTS']):\n",
    "            try:\n",
    "                stock_data = yf.download(ticker, start=start_date, end=end_date, auto_adjust=True, progress=False)\n",
    "                if stock_data.empty:\n",
    "                    raise ValueError(f\"No data for {ticker} within the specified date range.\")\n",
    "                data[ticker] = stock_data\n",
    "                logging.info(f\"Successfully fetched data for {ticker}. Rows: {len(stock_data)}\")\n",
    "                break # Exit retry loop on success\n",
    "            except Exception as e:\n",
    "                logging.warning(f\"Attempt {attempt+1}/{CONFIG['RETRY_ATTEMPTS']} failed for {ticker}: {e}\")\n",
    "                if attempt < CONFIG['RETRY_ATTEMPTS'] - 1:\n",
    "                    time.sleep(CONFIG['RETRY_DELAY_SECONDS'])\n",
    "                else:\n",
    "                    logging.error(f\"Failed to fetch data for {ticker} after {CONFIG['RETRY_ATTEMPTS']} attempts. Error: {e}\")\n",
    "                    send_alert(f\"CRITICAL: Data Fetch Failure for {ticker}\", f\"Failed to download data for {ticker}. Error: {e}\")\n",
    "    return data\n",
    "\n",
    "# -------------------------------------\\n\",\n",
    "# Feature Engineering\\n\",\n",
    "# -------------------------------------\\n\",\n",
    "def prepare_features(data, ticker):\n",
    "    \"\"\"\n",
    "    Calculate returns, volatility, RSI, volume change as 1D arrays.\n",
    "    Ensures features are 2D arrays (samples, features) for HMM.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = data[ticker].copy()\n",
    "        if len(df) < 50: # Minimum data points for RSI (14) and other calculations\n",
    "            raise ValueError(f\"Insufficient historical data for {ticker}. Need at least 50 days.\")\n",
    "\n",
    "        # Compute features\n",
    "        df['Returns'] = df['Close'].pct_change()\n",
    "        df['Volatility'] = df['Returns'].rolling(window=20).std() * np.sqrt(252) # Annualized volatility\n",
    "        \n",
    "        # RSI using Pandas\n",
    "        delta = df['Close'].diff()\n",
    "        gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()\n",
    "        loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()\n",
    "        # Handle cases where loss is zero to avoid division by zero\n",
    "        rs = gain / loss.replace(0, np.nan) # Replace 0 with NaN, then NaNs will propagate\n",
    "        df['RSI'] = 100 - (100 / (1 + rs))\n",
    "\n",
    "        df['Volume_Change'] = df['Volume'].pct_change()\n",
    "\n",
    "        # Drop NaNs created by rolling windows and pct_change\n",
    "        df = df.dropna()\n",
    "\n",
    "        if df.empty:\n",
    "            raise ValueError(f\"No valid data after dropping NaNs for {ticker}. Check raw data completeness.\")\n",
    "        \n",
    "        # Select features to be used by HMM\n",
    "        feature_columns = ['Returns', 'Volatility', 'RSI', 'Volume_Change']\n",
    "        features = df[feature_columns].values # .values ensures it's a NumPy array\n",
    "\n",
    "        if features.ndim != 2:\n",
    "            raise ValueError(f\"Features must be 2D after selection, got {features.ndim}D for {ticker}.\")\n",
    "        if features.shape[1] != len(feature_columns):\n",
    "            raise ValueError(f\"Feature count mismatch for {ticker}. Expected {len(feature_columns)}, got {features.shape[1]}.\")\n",
    "\n",
    "        logging.info(f\"Features shape for {ticker}: {features.shape}. First 5 rows of features:\\\\n{features[:5]}\")\n",
    "        logging.info(f\"DataFrame shape after feature prep for {ticker}: {df.shape}\")\n",
    "\n",
    "        return df, features, df.index\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Feature preparation failed for {ticker}: {e}\")\n",
    "        send_alert(f\"ERROR: Feature Prep Failure: {ticker}\", f\"Error: {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# -------------------------------------\\n\",\n",
    "# HMM Model Training and Optimization\\n\",\n",
    "# -------------------------------------\\n\",\n",
    "def optimize_hmm(features):\n",
    "    \"\"\"\n",
    "    Optimizes the HMM by finding the best number of hidden states using BIC.\n",
    "    \"\"\"\n",
    "    min_states = CONFIG['HMM_MIN_STATES']\n",
    "    max_states = CONFIG['HMM_MAX_STATES']\n",
    "    best_bic = np.inf\n",
    "    best_model = None\n",
    "\n",
    "    logging.info(f\"Optimizing HMM for states from {min_states} to {max_states}...\")\n",
    "\n",
    "    # Ensure enough data for training\n",
    "    # A heuristic: need at least N * number_of_features samples. Let's use 10 * max_states.\n",
    "    if len(features) < max_states * 10: \n",
    "        logging.warning(f\"Insufficient data ({len(features)} samples) for HMM optimization with up to {max_states} states. Skipping comprehensive optimization.\")\n",
    "        # Fallback to a default model if not enough data for comprehensive optimization\n",
    "        try:\n",
    "            # Try to fit with minimum states\n",
    "            default_model = GaussianHMM(n_components=min_states, covariance_type=\"diag\", n_iter=100, tol=0.01, init_params=\"s\", random_state=42)\n",
    "            default_model.fit(features)\n",
    "            logging.info(f\"Falling back to default HMM with {min_states} states due to insufficient data.\")\n",
    "            return default_model\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to fit default HMM with {min_states} states: {e}\")\n",
    "            send_alert(\"ERROR: HMM Default Fit Failed\", f\"Could not fit default HMM model. Error: {e}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "    for n_components in range(min_states, max_states + 1):\n",
    "        try:\n",
    "            # Initialize with random_state for reproducibility, but it's often better to try multiple initializations\n",
    "            # For \\\"life or death\\\", we'll stick to a simple approach.\n",
    "            model = GaussianHMM(n_components=n_components, covariance_type=\"diag\", n_iter=100, tol=0.01, init_params=\"s\", random_state=42)\n",
    "            model.fit(features)\n",
    "            \n",
    "            # Calculate BIC\n",
    "            log_likelihood = model.score(features) # This is log-likelihood\n",
    "            \n",
    "            # Number of parameters in GaussianHMM:\n",
    "            # n_components * (n_components - 1) for transition matrix (pi)\n",
    "            # n_components - 1 for start probabilities (A)\n",
    "            # n_components * n_features for means (mu)\n",
    "            # n_components * n_features for diagonal covariances (sigma)\n",
    "            # Total parameters (k)\n",
    "            n_features = features.shape[1]\n",
    "            k = (n_components * (n_components - 1)) + (n_components - 1) + (n_components * n_features) + (n_components * n_features)\n",
    "            \n",
    "            bic = -2 * log_likelihood + k * np.log(len(features))\n",
    "\n",
    "            logging.info(f\"HMM with {n_components} states: Log-Likelihood = {log_likelihood:.2f}, BIC = {bic:.2f}\")\n",
    "\n",
    "            if bic < best_bic:\n",
    "                best_bic = bic\n",
    "                best_model = model\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Failed to train HMM with {n_components} states: {e}. Skipping this state count.\")\n",
    "            continue # Try next number of states\n",
    "\n",
    "    if best_model is None:\n",
    "        logging.error(\"Failed to train any HMM model during optimization. Check data and state range.\")\n",
    "        send_alert(\"CRITICAL: HMM Optimization Failure\", \"Could not train any HMM model within the specified state range.\")\n",
    "        return None\n",
    "    \n",
    "    logging.info(f\"Optimal HMM chosen with {best_model.n_components} states (BIC: {best_bic:.2f}).\")\n",
    "    return best_model\n",
    "\n",
    "# -------------------------------------\\n\",\n",
    "# Signal Generation\\n\",\n",
    "# -------------------------------------\\n\",\n",
    "\n",
    "# import pandas as pd # Already imported\n",
    "# import numpy as np # Already imported\n",
    "# import logging # Already imported\n",
    "\n",
    "def generate_signals(df, hidden_states, index_from_prep):\n",
    "    ticker_name = df.index.name if hasattr(df, 'index') and df.index.name else \"current_ticker\"\n",
    "\n",
    "    try:\n",
    "        logging.info(f\"[{ticker_name}] ENTERING generate_signals. Initial df rows: {len(df)}\")\n",
    "        \n",
    "        if not df.index.is_unique:\n",
    "            logging.error(f\"[{ticker_name}] !!! CRITICAL WARNING !!! Initial DataFrame 'df' index for {ticker_name} IS NOT UNIQUE!\")\n",
    "            # This case is not being hit based on current logs, but good to keep.\n",
    "        else:\n",
    "            logging.info(f\"[{ticker_name}] Initial DataFrame 'df' index for {ticker_name} is unique. Proceeding.\")\n",
    "\n",
    "        df_temp = df.copy()\n",
    "        \n",
    "        if len(hidden_states) != len(df_temp.index):\n",
    "             error_msg = f\"Hidden states length ({len(hidden_states)}) does not match df_temp index length ({len(df_temp.index)}).\"\n",
    "             logging.error(f\"[{ticker_name}] CRITICAL ALIGNMENT ISSUE (hidden_states vs df_temp.index): {error_msg}\")\n",
    "             raise ValueError(error_msg)\n",
    "        df_temp['State'] = pd.Series(hidden_states, index=df_temp.index) \n",
    "        logging.info(f\"[{ticker_name}] Added 'State' column. df_temp rows: {len(df_temp)}\")\n",
    "        \n",
    "        # ... (state_means_returns, signal_map, df_temp['Signal'] - condensed, no changes) ...\n",
    "        state_means_returns = {}\n",
    "        if 'Returns' not in df_temp.columns:\n",
    "            error_msg = \"'Returns' column not found.\"\n",
    "            logging.error(f\"[{ticker_name}] {error_msg}\"); raise ValueError(error_msg)\n",
    "        unique_states = df_temp['State'].unique()\n",
    "        if df_temp.empty: logging.warning(f\"[{ticker_name}] DataFrame empty before state means.\")\n",
    "        elif len(unique_states) == 0 : logging.warning(f\"[{ticker_name}] 'State' column no unique values.\")\n",
    "        for s in unique_states:\n",
    "            subset_df = df_temp[df_temp['State'] == s]\n",
    "            state_means_returns[s] = 0.0 if subset_df.empty or subset_df['Returns'].isnull().all() else subset_df['Returns'].mean()\n",
    "        sorted_states = sorted(state_means_returns, key=state_means_returns.get)\n",
    "        signal_map = {}\n",
    "        if len(sorted_states) > 0:\n",
    "            signal_map[sorted_states[-1]] = 1 \n",
    "            if len(sorted_states) > 1: signal_map[sorted_states[0]] = -1\n",
    "            for i in range(1, len(sorted_states) - 1): signal_map[sorted_states[i]] = 0 \n",
    "        else: \n",
    "            logging.warning(f\"[{ticker_name}] No states for signal mapping.\"); return None\n",
    "        df_temp['Signal'] = df_temp['State'].map(signal_map).fillna(0)\n",
    "        logging.info(f\"[{ticker_name}] Signal map: {signal_map}, Last 5 signals:\\\\n{df_temp['Signal'].tail()}\")\n",
    "        \n",
    "        # --- Position Sizing ---\\n\",\n",
    "        df_temp['Adj_Volatility'] = df_temp['Volatility'].reindex(df_temp.index).replace([np.inf, -np.inf], np.nan).fillna(df_temp['Volatility'].reindex(df_temp.index).mean())\n",
    "        df_temp['Position_Size'] = np.clip(1 / (df_temp['Adj_Volatility'] * 100).replace(0, np.nan).fillna(0.01), CONFIG['POSITION_SIZE_MIN'], CONFIG['POSITION_SIZE_MAX'])\n",
    "        try:\n",
    "            df_temp['Position'] = df_temp['Signal'].reindex(df_temp.index) * df_temp['Position_Size'].reindex(df_temp.index)\n",
    "            logging.info(f\"[{ticker_name}] DEBUG: Calculated 'Position'.\")\n",
    "        except Exception as e_pos:\n",
    "            logging.error(f\"[{ticker_name}] ERROR calculating 'Position': {e_pos}\"); raise\n",
    "        df_temp['Position'] = df_temp['Position'].clip(-CONFIG['MAX_PORTFOLIO_EXPOSURE'], CONFIG['MAX_PORTFOLIO_EXPOSURE'])\n",
    "        \n",
    "        # --- Stop-Loss ---\\n\",\n",
    "        close_shifted = df_temp['Close'].shift(1).reindex(df_temp.index) \n",
    "        df_temp['Stop_Loss_Long_Price'] = close_shifted * (1 - CONFIG['STOP_LOSS_PERCENTAGE'])\n",
    "        df_temp['Stop_Loss_Short_Price'] = close_shifted * (1 + CONFIG['STOP_LOSS_PERCENTAGE'])\n",
    "        df_temp['Daily_Exit_Condition'] = False \n",
    "        \n",
    "        # --- Long Stop-Loss Condition ---\\n\",\n",
    "        logging.info(f\"[{ticker_name}] DEBUG: Calculating long SL.\")\n",
    "        try:\n",
    "            s1_long = (df_temp['Signal'].shift(1).reindex(df_temp.index)) > 0\n",
    "            logging.info(f\"[{ticker_name}] DEBUG: s1_long defined.\")\n",
    "            \n",
    "            op_low = df_temp['Low'].reindex(df_temp.index)\n",
    "            op_sl_long = df_temp['Stop_Loss_Long_Price'].reindex(df_temp.index)\n",
    "            \n",
    "            logging.info(f\"[{ticker_name}] DEBUG: op_low type: {type(op_low)}, ndim: {op_low.ndim}, shape: {op_low.shape}\")\n",
    "            logging.info(f\"[{ticker_name}] DEBUG: op_sl_long type: {type(op_sl_long)}, ndim: {op_sl_long.ndim}, shape: {op_sl_long.shape}\")\n",
    "            \n",
    "            op_low_vals = op_low.values\n",
    "            op_sl_long_vals = op_sl_long.values\n",
    "            \n",
    "            logging.info(f\"[{ticker_name}] DEBUG: op_low_vals ndim: {op_low_vals.ndim}, shape: {op_low_vals.shape}\")\n",
    "            logging.info(f\"[{ticker_name}] DEBUG: op_sl_long_vals ndim: {op_sl_long_vals.ndim}, shape: {op_sl_long_vals.shape}\")\n",
    "\n",
    "            # Ensure operands for <= are 1D\n",
    "            if op_low_vals.ndim > 1: op_low_vals = op_low_vals.squeeze()\n",
    "            if op_sl_long_vals.ndim > 1: op_sl_long_vals = op_sl_long_vals.squeeze()\n",
    "            \n",
    "            # Final check on shapes before comparison\n",
    "            logging.info(f\"[{ticker_name}] DEBUG: SQUEEZED op_low_vals ndim: {op_low_vals.ndim}, shape: {op_low_vals.shape}\")\n",
    "            logging.info(f\"[{ticker_name}] DEBUG: SQUEEZED op_sl_long_vals ndim: {op_sl_long_vals.ndim}, shape: {op_sl_long_vals.shape}\")\n",
    "\n",
    "            if not (op_low_vals.shape == op_sl_long_vals.shape and op_low_vals.ndim == 1):\n",
    "                raise ValueError(f\"[{ticker_name}] Shape mismatch or not 1D after squeeze for .values comparison: op_low {op_low_vals.shape}, op_sl_long {op_sl_long_vals.shape}\")\n",
    "\n",
    "            logging.info(f\"[{ticker_name}] DEBUG: Attempting comparison for s2_long using .values: op_low_vals <= op_sl_long_vals\")\n",
    "            s2_long_values = op_low_vals <= op_sl_long_vals\n",
    "            s2_long = pd.Series(s2_long_values, index=df_temp.index, name=\"s2_long_condition\")\n",
    "            logging.info(f\"[{ticker_name}] DEBUG: s2_long defined via .values comparison. Shape of result: {s2_long_values.shape}\")\n",
    "            \n",
    "            logging.info(f\"[{ticker_name}] DEBUG: Aligning s1_long and s2_long for '&'. Pre-align: s1_long.index.equals(s2_long.index): {s1_long.index.equals(s2_long.index)}\")\n",
    "            s1_long_aligned, s2_long_aligned = s1_long.align(s2_long, join='outer', axis=0, copy=False, fill_value=False)\n",
    "            logging.info(f\"[{ticker_name}] DEBUG: s1_long & s2_long aligned. Post-align: s1_aligned.equals(s2_aligned): {s1_long_aligned.index.equals(s2_long_aligned.index)}\")\n",
    "\n",
    "            long_condition = s1_long_aligned & s2_long_aligned\n",
    "            df_temp.loc[long_condition, 'Daily_Exit_Condition'] = True\n",
    "            logging.info(f\"[{ticker_name}] DEBUG: Long SL condition applied.\")\n",
    "        except Exception as e_long_sl:\n",
    "            logging.error(f\"[{ticker_name}] DEBUG ERROR during long SL: {e_long_sl}\")\n",
    "            # import traceback\n",
    "            # logging.error(f\"[{ticker_name}] Traceback for long_sl error:\\\\n{traceback.format_exc()}\")\n",
    "            raise \n",
    "        \n",
    "        # --- Short Stop-Loss Condition (Apply similar .values logic and squeezing) ---\\n\",\n",
    "        logging.info(f\"[{ticker_name}] DEBUG: Calculating short SL.\")\n",
    "        try:\n",
    "            s1_short = (df_temp['Signal'].shift(1).reindex(df_temp.index)) < 0\n",
    "            logging.info(f\"[{ticker_name}] DEBUG: s1_short defined.\")\n",
    "\n",
    "            op_high = df_temp['High'].reindex(df_temp.index)\n",
    "            op_sl_short = df_temp['Stop_Loss_Short_Price'].reindex(df_temp.index)\n",
    "\n",
    "            logging.info(f\"[{ticker_name}] DEBUG: op_high type: {type(op_high)}, ndim: {op_high.ndim}, shape: {op_high.shape}\")\n",
    "            logging.info(f\"[{ticker_name}] DEBUG: op_sl_short type: {type(op_sl_short)}, ndim: {op_sl_short.ndim}, shape: {op_sl_short.shape}\")\n",
    "\n",
    "            op_high_vals = op_high.values\n",
    "            op_sl_short_vals = op_sl_short.values\n",
    "\n",
    "            logging.info(f\"[{ticker_name}] DEBUG: op_high_vals ndim: {op_high_vals.ndim}, shape: {op_high_vals.shape}\")\n",
    "            logging.info(f\"[{ticker_name}] DEBUG: op_sl_short_vals ndim: {op_sl_short_vals.ndim}, shape: {op_sl_short_vals.shape}\")\n",
    "\n",
    "            if op_high_vals.ndim > 1: op_high_vals = op_high_vals.squeeze()\n",
    "            if op_sl_short_vals.ndim > 1: op_sl_short_vals = op_sl_short_vals.squeeze()\n",
    "            \n",
    "            logging.info(f\"[{ticker_name}] DEBUG: SQUEEZED op_high_vals ndim: {op_high_vals.ndim}, shape: {op_high_vals.shape}\")\n",
    "            logging.info(f\"[{ticker_name}] DEBUG: SQUEEZED op_sl_short_vals ndim: {op_sl_short_vals.ndim}, shape: {op_sl_short_vals.shape}\")\n",
    "            \n",
    "            if not (op_high_vals.shape == op_sl_short_vals.shape and op_high_vals.ndim == 1):\n",
    "                raise ValueError(f\"[{ticker_name}] Shape mismatch or not 1D after squeeze for .values comparison: op_high {op_high_vals.shape}, op_sl_short {op_sl_short_vals.shape}\")\n",
    "\n",
    "\n",
    "            logging.info(f\"[{ticker_name}] DEBUG: Attempting comparison for s2_short using .values: op_high_vals >= op_sl_short_vals\")\n",
    "            s2_short_values = op_high_vals >= op_sl_short_vals\n",
    "            s2_short = pd.Series(s2_short_values, index=df_temp.index, name=\"s2_short_condition\")\n",
    "            logging.info(f\"[{ticker_name}] DEBUG: s2_short defined via .values comparison. Shape of result: {s2_short_values.shape}\")\n",
    "            \n",
    "            logging.info(f\"[{ticker_name}] DEBUG: Aligning s1_short and s2_short for '&'. Pre-align: s1_short.index.equals(s2_short.index): {s1_short.index.equals(s2_short.index)}\")\n",
    "            s1_short_aligned, s2_short_aligned = s1_short.align(s2_short, join='outer', axis=0, copy=False, fill_value=False)\n",
    "            logging.info(f\"[{ticker_name}] DEBUG: s1_short & s2_short aligned. Post-align: s1_aligned.equals(s2_aligned): {s1_short_aligned.index.equals(s2_short_aligned.index)}\")\n",
    "            \n",
    "            short_condition = s1_short_aligned & s2_short_aligned\n",
    "            df_temp.loc[short_condition, 'Daily_Exit_Condition'] = True \n",
    "            logging.info(f\"[{ticker_name}] DEBUG: Short SL condition applied.\")\n",
    "        except Exception as e_short_sl:\n",
    "            logging.error(f\"[{ticker_name}] DEBUG ERROR during short SL: {e_short_sl}\")\n",
    "            # import traceback\n",
    "            # logging.error(f\"[{ticker_name}] Traceback for short_sl error:\\\\n{traceback.format_exc()}\")\n",
    "            raise\n",
    "        \n",
    "        # --- Final Position ---\\n\",\n",
    "        df_temp['Final_Position'] = df_temp['Position'].shift(1).reindex(df_temp.index)\n",
    "        try:\n",
    "            daily_exit_cond_series = df_temp['Daily_Exit_Condition'].reindex(df_temp.index)\n",
    "            df_temp.loc[daily_exit_cond_series, 'Final_Position'] = 0\n",
    "            logging.info(f\"[{ticker_name}] DEBUG: Applied 'Daily_Exit_Condition' to 'Final_Position'.\")\n",
    "        except Exception as e_final_pos:\n",
    "            logging.error(f\"[{ticker_name}] ERROR applying 'Daily_Exit_Condition': {e_final_pos}\"); raise\n",
    "        df_temp['Final_Position'].fillna(0, inplace=True)\n",
    "        \n",
    "        logging.info(f\"[{ticker_name}] Signal generation completed. df_temp rows: {len(df_temp)}\")\n",
    "        return df_temp\n",
    "        \n",
    "    except Exception as e:\n",
    "        logging.error(f\"[{ticker_name}] Overall signal generation failed: {e}\")\n",
    "        # import traceback\n",
    "        # logging.error(f\"[{ticker_name}] Traceback for overall error:\\\\n{traceback.format_exc()}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "# -------------------------------------\\n\",\n",
    "# Backtesting\\n\",\n",
    "# -------------------------------------\\n\",\n",
    "def backtest_strategy(processed_data, tickers, benchmark_symbol): # MODIFIED SIGNATURE\n",
    "    \"\"\"Backtest strategy across portfolio.\"\"\"\n",
    "    try:\n",
    "        # Find the common index (dates) across all processed dataframes\n",
    "        common_index = None\n",
    "        for ticker in tickers: # 'tickers' here are the strategy tickers\n",
    "            if ticker in processed_data and not processed_data[ticker].empty:\n",
    "                if common_index is None:\n",
    "                    common_index = processed_data[ticker].index\n",
    "                else:\n",
    "                    common_index = common_index.intersection(processed_data[ticker].index)\n",
    "            else:\n",
    "                logging.warning(f\"No processed data or empty DataFrame for {ticker} during backtest index alignment.\")\n",
    "        \n",
    "        if common_index is None or common_index.empty:\n",
    "            raise ValueError(\"No common dates found across all strategy tickers for backtesting. Check data fetching and processing.\")\n",
    "\n",
    "        # Ensure the common index is sorted\n",
    "        common_index = common_index.sort_values()\n",
    "\n",
    "        portfolio = pd.DataFrame(index=common_index)\n",
    "        portfolio['Portfolio_Returns'] = 0.0\n",
    "        \n",
    "        # NEW BENCHMARK LOGIC:\n",
    "        portfolio['Market_Returns'] = 0.0 # Initialize to 0.0\n",
    "        market_returns_set = False\n",
    "\n",
    "        if benchmark_symbol in processed_data and \\\n",
    "           not processed_data[benchmark_symbol].empty and \\\n",
    "           'Returns' in processed_data[benchmark_symbol].columns:\n",
    "            \n",
    "            benchmark_df_copy = processed_data[benchmark_symbol].copy() # Work on a copy for index modification\n",
    "            \n",
    "            if not isinstance(benchmark_df_copy.index, pd.DatetimeIndex):\n",
    "                try:\n",
    "                    benchmark_df_copy.index = pd.to_datetime(benchmark_df_copy.index)\n",
    "                except Exception as e:\n",
    "                    logging.error(f\"Failed to convert benchmark {benchmark_symbol} index to DatetimeIndex: {e}\")\n",
    "            \n",
    "            if isinstance(benchmark_df_copy.index, pd.DatetimeIndex):\n",
    "                benchmark_returns_series = benchmark_df_copy['Returns']\n",
    "                portfolio['Market_Returns'] = benchmark_returns_series.reindex(common_index).fillna(0.0)\n",
    "                logging.info(f\"Using {benchmark_symbol} returns as market benchmark.\")\n",
    "                market_returns_set = True\n",
    "            else:\n",
    "                logging.warning(f\"Market benchmark {benchmark_symbol} index is not DatetimeIndex after attempting conversion. Market returns set to 0.\")\n",
    "                \n",
    "        else:\n",
    "            logging.warning(f\"Market benchmark {benchmark_symbol} not found in processed_data or 'Returns' column missing. Market returns set to 0.\")\n",
    "\n",
    "        if not market_returns_set: # Ensure it is set if any path above failed to set it.\n",
    "             portfolio['Market_Returns'] = 0.0\n",
    "        # END NEW BENCHMARK LOGIC\n",
    "\n",
    "        # Calculate portfolio returns based on individual stock strategy returns\n",
    "        active_tickers_count = 0\n",
    "        for ticker in tickers: # 'tickers' here are the strategy tickers\n",
    "            if ticker in processed_data and not processed_data[ticker].empty and 'Final_Position' in processed_data[ticker] and 'Returns' in processed_data[ticker]:\n",
    "                df = processed_data[ticker].loc[common_index].copy()\n",
    "                # Ensure 'Final_Position' and 'Returns' columns are numeric and handle NaNs\n",
    "                df['Final_Position'] = pd.to_numeric(df['Final_Position'], errors='coerce').fillna(0)\n",
    "                df['Returns'] = pd.to_numeric(df['Returns'], errors='coerce').fillna(0)\n",
    "                \n",
    "                df['Strategy_Returns'] = df['Final_Position'] * df['Returns']\n",
    "                \n",
    "                # Sum individual strategy returns. Will be normalized later by active_tickers_count.\n",
    "                portfolio['Portfolio_Returns'] += df['Strategy_Returns']\n",
    "                active_tickers_count += 1\n",
    "            else:\n",
    "                logging.warning(f\"Skipping {ticker} in backtest due to missing or invalid processed data for portfolio calculation.\")\n",
    "        \n",
    "        if active_tickers_count > 0:\n",
    "            portfolio['Portfolio_Returns'] /= active_tickers_count # Average returns across active tickers\n",
    "        else:\n",
    "            # If no tickers contributed to portfolio returns, set to zero to avoid NaN issues.\n",
    "            # Or raise ValueError if this is considered a critical failure.\n",
    "            logging.warning(\"No valid tickers contributed to portfolio returns. Portfolio returns set to 0.\")\n",
    "            portfolio['Portfolio_Returns'] = 0.0\n",
    "\n",
    "\n",
    "        # Ensure cumulative product starts from 1 for initial equity\n",
    "        portfolio['Cumulative_Strategy_Returns'] = (1 + portfolio['Portfolio_Returns']).cumprod()\n",
    "        portfolio['Cumulative_Market_Returns'] = (1 + portfolio['Market_Returns']).cumprod()\n",
    "\n",
    "        # Handle initial NaNs from cumprod if the first returns are NaN (unlikely if data is clean)\n",
    "        portfolio['Cumulative_Strategy_Returns'] = portfolio['Cumulative_Strategy_Returns'].fillna(1.0)\n",
    "        portfolio['Cumulative_Market_Returns'] = portfolio['Cumulative_Market_Returns'].fillna(1.0)\n",
    "\n",
    "        logging.info(\"Backtest completed successfully.\")\n",
    "        return portfolio\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Backtest failed: {e}\")\n",
    "        send_alert(\"CRITICAL: Backtest Failure\", f\"Error during backtesting: {e}\")\n",
    "        return None\n",
    "\n",
    "# -------------------------------------\\n\",\n",
    "# Performance Metrics\\n\",\n",
    "# -------------------------------------\\n\",\n",
    "def performance_metrics(portfolio):\n",
    "    \"\"\"Calculate Sharpe ratio and maximum drawdown.\"\"\"\n",
    "    try:\n",
    "        # Ensure portfolio is not empty\n",
    "        if portfolio.empty or 'Portfolio_Returns' not in portfolio:\n",
    "            logging.warning(\"Portfolio is empty or missing 'Portfolio_Returns', cannot calculate performance metrics.\")\n",
    "            return 0.0, 0.0\n",
    "\n",
    "        returns = portfolio['Portfolio_Returns']\n",
    "        \n",
    "        # Handle cases where std is zero (e.g., no trading or no variation in returns)\n",
    "        annualized_volatility = returns.std() * np.sqrt(252) # Assuming 252 trading days\n",
    "        sharpe = (returns.mean() * 252) / annualized_volatility if annualized_volatility != 0 else 0\n",
    "        \n",
    "        cum_returns = portfolio['Cumulative_Strategy_Returns']\n",
    "        if cum_returns.empty:\n",
    "            logging.warning(\"Cumulative returns series is empty, cannot calculate drawdown.\")\n",
    "            return sharpe, 0.0\n",
    "            \n",
    "        peak = cum_returns.cummax()\n",
    "        # Handle division by zero for drawdown if peak is 0 (e.g., all negative returns)\n",
    "        drawdown = (cum_returns - peak) / peak.replace(0, np.nan) # Replace 0 peak with NaN to avoid DivByZero\n",
    "        drawdown = drawdown.fillna(0) # Fill NaNs that arise from peak being NaN (e.g. if all returns are NaN initially)\n",
    "        max_drawdown = drawdown.min()\n",
    "\n",
    "\n",
    "        logging.info(f\"Calculated performance metrics: Sharpe={sharpe:.2f}, Max Drawdown={max_drawdown:.2%}\")\n",
    "        return sharpe, max_drawdown\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error calculating performance metrics: {e}\")\n",
    "        send_alert(\"ERROR: Performance Metrics Failure\", f\"Error: {e}\")\n",
    "        return None, None\n",
    "\n",
    "# -------------------------------------\\n\",\n",
    "# Paper Trading\\n\",\n",
    "# -------------------------------------\\n\",\n",
    "def paper_trade(tickers, processed_data): # `tickers` here refers to the list of strategy tickers\n",
    "    \"\"\"Submit paper trading orders via Alpaca.\"\"\"\n",
    "    try:\n",
    "        # Initialize Alpaca API\n",
    "        api = REST(CONFIG['ALPACA_API_KEY'], CONFIG['ALPACA_SECRET_KEY'], base_url=CONFIG['ALPACAY_BASE_URL'])\n",
    "        account = api.get_account()\n",
    "        logging.info(f\"Alpaca Account Status: {account.status}, Equity: ${float(account.equity):.2f}\")\n",
    "\n",
    "        # Get current open positions\n",
    "        current_positions = {p.symbol: float(p.qty) for p in api.list_positions()}\n",
    "        logging.info(f\"Current Alpaca positions: {current_positions}\")\n",
    "\n",
    "        for ticker in tickers: # Iterate over strategy tickers\n",
    "            if ticker not in processed_data:\n",
    "                logging.warning(f\"Skipping paper trade for {ticker}: no processed data.\")\n",
    "                continue\n",
    "\n",
    "            df_ticker = processed_data[ticker]\n",
    "            if df_ticker.empty:\n",
    "                logging.warning(f\"Skipping paper trade for {ticker}: DataFrame is empty.\")\n",
    "                continue\n",
    "            \n",
    "            # Ensure 'Signal', 'Close', 'Position_Size' are present\n",
    "            if not all(col in df_ticker.columns for col in ['Signal', 'Close', 'Position_Size']):\n",
    "                logging.warning(f\"Skipping paper trade for {ticker}: Missing required columns (Signal, Close, or Position_Size).\")\n",
    "                continue\n",
    "\n",
    "\n",
    "            # Get the latest signal, calculated position size, and latest closing price\n",
    "            latest_signal = df_ticker['Signal'].iloc[-1]\n",
    "            latest_close = df_ticker['Close'].iloc[-1]\n",
    "            latest_position_size = df_ticker['Position_Size'].iloc[-1]\n",
    "            \n",
    "            if pd.isna(latest_signal) or pd.isna(latest_close) or pd.isna(latest_position_size):\n",
    "                logging.warning(f\"Latest signal, close, or position_size for {ticker} is NaN. Skipping trade for this ticker.\")\n",
    "                continue\n",
    "\n",
    "            # Calculate target quantity \n",
    "            base_qty_per_trade = 10 # This could be a config parameter\n",
    "            target_qty = int(base_qty_per_trade * latest_position_size)\n",
    "            \n",
    "            if target_qty <= 0:\n",
    "                logging.info(f\"Calculated target quantity for {ticker} is zero or negative ({target_qty}). Skipping order.\")\n",
    "                continue\n",
    "\n",
    "            current_qty = current_positions.get(ticker, 0)\n",
    "            \n",
    "            action = 'none'\n",
    "            order_side = None\n",
    "            order_qty = 0\n",
    "\n",
    "            if latest_signal == 1: # Buy Signal\n",
    "                if current_qty < target_qty: \n",
    "                    order_side = 'buy'\n",
    "                    order_qty = target_qty - current_qty \n",
    "                    action = f\"BUY {order_qty} shares of {ticker} to go long\"\n",
    "                elif current_qty > target_qty: \n",
    "                    order_side = 'sell'\n",
    "                    order_qty = current_qty - target_qty\n",
    "                    action = f\"SELL {order_qty} shares of {ticker} to reduce long\"\n",
    "            elif latest_signal == -1: # Sell/Short Signal\n",
    "                if current_qty > -target_qty: \n",
    "                    order_side = 'sell'\n",
    "                    order_qty = abs(-target_qty - current_qty) \n",
    "                    action = f\"SELL {order_qty} shares of {ticker} to go short\"\n",
    "                elif current_qty < -target_qty: \n",
    "                    order_side = 'buy'\n",
    "                    order_qty = abs(current_qty - (-target_qty))\n",
    "                    action = f\"BUY {order_qty} shares of {ticker} to reduce short\"\n",
    "            else: # Signal is 0 (Hold/Neutral)\n",
    "                if current_qty != 0: \n",
    "                    order_side = 'sell' if current_qty > 0 else 'buy'\n",
    "                    order_qty = abs(current_qty)\n",
    "                    action = f\"{'SELL' if current_qty > 0 else 'BUY'} {order_qty} shares of {ticker} to close position\"\n",
    "\n",
    "            if order_qty > 0 and order_side:\n",
    "                logging.info(f\"Paper trade: {action}\")\n",
    "                api.submit_order(\n",
    "                    symbol=ticker, \n",
    "                    qty=order_qty, \n",
    "                    side=order_side, \n",
    "                    type='market', \n",
    "                    time_in_force='day'\n",
    "                )\n",
    "            else:\n",
    "                logging.info(f\"Paper trade: No action needed for {ticker}. Current Qty: {current_qty}, Signal: {latest_signal}, Target Qty: {target_qty}\")\n",
    "\n",
    "        logging.info(\"Paper trading operations completed.\")\n",
    "    except Exception as e:\n",
    "        # NOTE: The original log showed: \"ERROR - Paper trading failed: name 'SectorPerformances' is not defined\"\n",
    "        # This error means 'SectorPerformances' was used somewhere in the original executed code for paper trading\n",
    "        # but is not defined. You will need to resolve this in your actual environment if it persists.\n",
    "        # The function provided here does not show 'SectorPerformances'.\n",
    "        logging.error(f\"Paper trading failed: {e}\")\n",
    "        send_alert(\"CRITICAL: Paper Trading Failure\", f\"Error during Alpaca paper trading: {e}\")\n",
    "\n",
    "# -------------------------------------\\n\",\n",
    "# Data Storage\\n\",\n",
    "# -------------------------------------\\n\",\n",
    "def save_data(data_dict, tickers_to_save): # Modified to accept data_dict and list of tickers\n",
    "    \"\"\"Save data to local CSV in a dedicated directory.\"\"\"\n",
    "    for ticker_key in tickers_to_save: # Iterate over the keys you want to save\n",
    "        try:\n",
    "            if ticker_key in data_dict and not data_dict[ticker_key].empty:\n",
    "                file_path = os.path.join(CONFIG['DATA_DIR'], f\"{ticker_key}_processed_data.csv\")\n",
    "                data_dict[ticker_key].to_csv(file_path)\n",
    "                logging.info(f\"Saved processed data for {ticker_key} to {file_path}\")\n",
    "            else:\n",
    "                logging.warning(f\"No processed data to save for {ticker_key}.\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Failed to save processed data for {ticker_key}: {e}\")\n",
    "            send_alert(f\"ERROR: Data Save Failure: {ticker_key}\", f\"Error: {e}\")\n",
    "\n",
    "# -------------------------------------\\n\",\n",
    "# Main Function\\n\",\n",
    "# -------------------------------------\\n\",\n",
    "def main():\n",
    "    \"\"\"Run the HMM trading strategy.\"\"\"\n",
    "    logging.info(\"Starting HMM trading strategy execution...\")\n",
    "    try:\n",
    "        validate_config()\n",
    "    except ValueError as e:\n",
    "        logging.critical(f\"Configuration error: {e}. Exiting.\")\n",
    "        send_alert(\"CRITICAL: Configuration Error\", str(e))\n",
    "        sys.exit(1) # Exit the script\n",
    "\n",
    "    # Parameters\n",
    "    # MODIFIED: Define strategy tickers and benchmark ticker\n",
    "    tickers = ['NVDA', 'MSTR', 'PLTR', 'TSLA'] # NVDA added, these are HMM strategy + benchmark\n",
    "    benchmark_ticker_symbol = 'SPY' # NVDA will be used as benchmark\n",
    "\n",
    "    end_date = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')\n",
    "    # If using a fixed start date like '2015-01-01', uncomment the line below\n",
    "    # start_date = '2015-01-01'\n",
    "    # Otherwise, use the dynamic lookback period:\n",
    "    start_date = (datetime.now() - timedelta(days=CONFIG['DATA_LOOKBACK_YEARS'] * 365)).strftime('%Y-%m-%d')\n",
    "\n",
    "\n",
    "    logging.info(f\"Fetching data for tickers: {tickers} from {start_date} to {end_date}\")\n",
    "    raw_data = fetch_data(tickers, start_date, end_date) # Fetch for all tickers including benchmark\n",
    "    \n",
    "    # Check if all necessary data was fetched\n",
    "    if not raw_data or any(tic not in raw_data for tic in tickers):\n",
    "        logging.critical(f\"Failed to fetch data for one or more tickers in {tickers}. Exiting.\")\n",
    "        send_alert(\"CRITICAL: Data Fetching Incomplete\", f\"Not all required historical data could be fetched for {tickers}.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    processed_data = {}\n",
    "    for ticker in tickers: # Loop includes all tickers (strategy + benchmark) for feature prep\n",
    "        if ticker not in raw_data or raw_data[ticker].empty:\n",
    "            logging.warning(f\"Raw data not available or empty for {ticker}. Skipping processing for this ticker.\")\n",
    "            send_alert(f\"WARNING: Skipping Ticker {ticker}\", f\"Raw data not available or empty for {ticker}.\")\n",
    "            continue\n",
    "\n",
    "        # Prepare features for all tickers (including benchmark, as 'Returns' are needed)\n",
    "        df, features, index = prepare_features(raw_data, ticker)\n",
    "        if df is None or features is None or index is None:\n",
    "            logging.error(f\"Skipping {ticker} due to feature preparation failure.\")\n",
    "            send_alert(f\"ERROR: Processing Failed {ticker}\", f\"Feature preparation failed for {ticker}. Check logs.\")\n",
    "            continue\n",
    "        \n",
    "        # Only apply HMM modeling and signal generation to strategy tickers (all tickers in this case as NVDA is both)\n",
    "        # If NVDA (benchmark) was NOT to be traded by HMM, you would add: if ticker != benchmark_ticker_symbol:\n",
    "        # But here, NVDA is part of the strategy AND the benchmark.\n",
    "        \n",
    "        if features.shape[0] < CONFIG['HMM_MAX_STATES'] * features.shape[1]: \n",
    "            logging.warning(f\"Insufficient features ({features.shape[0]} samples) for robust HMM training for {ticker}. Skipping HMM for this ticker.\")\n",
    "            send_alert(f\"WARNING: Insufficient Data for HMM {ticker}\", f\"Not enough data for robust HMM training for {ticker}. Skipping HMM for this ticker.\")\n",
    "            # Store the df with basic features (like 'Returns') even if HMM is skipped,\n",
    "            # especially if this ticker is the benchmark.\n",
    "            # However, for HMM-traded tickers, skipping HMM means no signals.\n",
    "            processed_data[ticker] = df # Store df with basic features, it will lack HMM signals if this path is taken.\n",
    "            continue\n",
    "\n",
    "\n",
    "        model_path = os.path.join(CONFIG['HMM_MODEL_DIR'], f\"{ticker}_hmm_model.pkl\")\n",
    "        retrain_needed = False\n",
    "        if datetime.now().weekday() == 0: \n",
    "            logging.info(f\"It's Monday. Retraining HMM for {ticker}.\")\n",
    "            retrain_needed = True\n",
    "        elif not os.path.exists(model_path):\n",
    "            logging.info(f\"HMM model for {ticker} not found. Training new model.\")\n",
    "            retrain_needed = True\n",
    "        \n",
    "        model = None\n",
    "        if retrain_needed:\n",
    "            model = optimize_hmm(features)\n",
    "            if model is None:\n",
    "                logging.error(f\"Failed to train or optimize HMM for {ticker}. Skipping signal generation.\")\n",
    "                send_alert(f\"ERROR: HMM Training Failure: {ticker}\", f\"Failed to train HMM for {ticker}.\")\n",
    "                processed_data[ticker] = df # Store basic df\n",
    "                continue\n",
    "            with open(model_path, \"wb\") as f: pickle.dump(model, f)\n",
    "            logging.info(f\"Saved new HMM model for {ticker} to {model_path}\")\n",
    "        else:\n",
    "            try:\n",
    "                with open(model_path, \"rb\") as f: model = pickle.load(f)\n",
    "                logging.info(f\"Loaded HMM model for {ticker} from {model_path}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Failed to load HMM model for {ticker}: {e}. Attempting to retrain.\")\n",
    "                send_alert(f\"ERROR: HMM Load Failure: {ticker}\", f\"Failed to load HMM for {ticker}. Error: {e}\")\n",
    "                model = optimize_hmm(features) \n",
    "                if model is None:\n",
    "                    logging.error(f\"Failed to retrain HMM for {ticker} after load failure. Skipping.\")\n",
    "                    processed_data[ticker] = df # Store basic df\n",
    "                    continue\n",
    "                with open(model_path, \"wb\") as f: pickle.dump(model, f)\n",
    "                logging.info(f\"Saved newly trained HMM model for {ticker} after load failure to {model_path}\")\n",
    "\n",
    "        try:\n",
    "            hidden_states = model.predict(features)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"HMM prediction failed for {ticker}: {e}. Skipping signal generation.\")\n",
    "            send_alert(f\"ERROR: HMM Prediction Failure: {ticker}\", f\"HMM prediction failed for {ticker}. Error: {e}\")\n",
    "            processed_data[ticker] = df # Store basic df\n",
    "            continue\n",
    "\n",
    "        df_with_signals = generate_signals(df, hidden_states, index) # df here is from prepare_features\n",
    "        if df_with_signals is None:\n",
    "            logging.error(f\"Skipping {ticker} due to signal generation failure.\")\n",
    "            send_alert(f\"ERROR: Signal Generation Failed {ticker}\", f\"Signal generation failed for {ticker}. Check logs.\")\n",
    "            processed_data[ticker] = df # Store basic df\n",
    "            continue\n",
    "        \n",
    "        if len(df_with_signals) >= 5 and df_with_signals['Signal'].iloc[-5:].nunique() == 1:\n",
    "            logging.warning(f\"Stagnant signals for {ticker}: Signals unchanged for the last 5 trading days. Consider model review.\")\n",
    "            send_alert(f\"WARNING: Stagnant Signals: {ticker}\", \"Signals unchanged for the last 5 trading days. Review strategy.\")\n",
    "        \n",
    "        processed_data[ticker] = df_with_signals\n",
    "\n",
    "    if not processed_data or not any(ticker in processed_data for ticker in tickers if ticker != benchmark_ticker_symbol): # Check if any strategy ticker got processed\n",
    "        logging.critical(\"No assets processed for trading strategy. Exiting.\")\n",
    "        send_alert(\"CRITICAL: No Processed Strategy Data\", \"No assets could be processed for generating trading signals for the strategy.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    save_data(processed_data, list(processed_data.keys())) # Save all data in processed_data\n",
    "\n",
    "    # MODIFIED: Pass benchmark_ticker_symbol to backtest_strategy\n",
    "    portfolio = backtest_strategy(processed_data, tickers, benchmark_ticker_symbol) \n",
    "    if portfolio is None or portfolio.empty:\n",
    "        logging.critical(\"Backtesting failed or resulted in empty portfolio. Exiting.\")\n",
    "        send_alert(\"CRITICAL: Backtest Empty/Failed\", \"Backtesting did not yield a valid portfolio.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    if not portfolio['Portfolio_Returns'].empty and portfolio['Portfolio_Returns'].iloc[-1] < CONFIG['DAILY_LOSS_THRESHOLD']:\n",
    "        logging.critical(f\"Daily portfolio loss ({portfolio['Portfolio_Returns'].iloc[-1]:.2%}) exceeds {CONFIG['DAILY_LOSS_THRESHOLD']:.2%}. Halting further actions.\")\n",
    "        send_alert(\"CRITICAL: Excessive Daily Loss\", f\"Portfolio loss ({portfolio['Portfolio_Returns'].iloc[-1]:.2%}) exceeds daily limit. Halting execution.\")\n",
    "        sys.exit(1) \n",
    "\n",
    "    sharpe, max_drawdown = performance_metrics(portfolio)\n",
    "    if sharpe is not None and max_drawdown is not None:\n",
    "        final_strategy_return = (portfolio['Cumulative_Strategy_Returns'].iloc[-1] - 1) if not portfolio['Cumulative_Strategy_Returns'].empty else 0\n",
    "        final_market_return = (portfolio['Cumulative_Market_Returns'].iloc[-1] - 1) if not portfolio['Cumulative_Market_Returns'].empty else 0\n",
    "\n",
    "        logging.info(f\"FINAL PERFORMANCE: Sharpe Ratio: {sharpe:.2f}\")\n",
    "        logging.info(f\"FINAL PERFORMANCE: Max Drawdown: {max_drawdown:.2%}\")\n",
    "        logging.info(f\"FINAL PERFORMANCE: Strategy Return: {final_strategy_return:.2%}\")\n",
    "        logging.info(f\"FINAL PERFORMANCE: Market Return (Benchmark: {benchmark_ticker_symbol}): {final_market_return:.2%}\") # Clarify benchmark\n",
    "        \n",
    "        send_alert(\"Daily Trading Report\",\n",
    "                   f\"Strategy Run Complete.\\\\n\"\n",
    "                   f\"Sharpe Ratio: {sharpe:.2f}\\\\n\"\n",
    "                   f\"Max Drawdown: {max_drawdown:.2%}\\\\n\"\n",
    "                   f\"Strategy Return: {final_strategy_return:.2%}\\\\n\"\n",
    "                   f\"Market Return (Benchmark: {benchmark_ticker_symbol}): {final_market_return:.2%}\\\\n\" # Clarify benchmark\n",
    "                   f\"Check {CONFIG['LOG_FILE']} and {CONFIG['PERFORMANCE_PLOT_FILE']} for details.\")\n",
    "    else:\n",
    "        logging.error(\"Could not calculate final performance metrics.\")\n",
    "        send_alert(\"ERROR: Final Performance Calculation\", \"Could not calculate final performance metrics.\")\n",
    "\n",
    "\n",
    "    logging.info(\"Initiating paper trading operations...\")\n",
    "    # Paper trading will be attempted for all tickers in the 'tickers' list passed,\n",
    "    # which now includes NVDA. If NVDA has signals in its processed_data entry, it will be traded.\n",
    "    paper_trade(tickers, processed_data) \n",
    "\n",
    "    try:\n",
    "        plt.figure(figsize=(14, 7))\n",
    "        plt.plot(portfolio.index, portfolio['Cumulative_Market_Returns'], label=f'Market ({benchmark_ticker_symbol})', color='blue', alpha=0.7) # Clarify benchmark\n",
    "        plt.plot(portfolio.index, portfolio['Cumulative_Strategy_Returns'], label='HMM Strategy', color='red')\n",
    "        #plt.title(f'HMM Strategy Performance vs {benchmark_ticker_symbol} - {\\\", \\\".join(tickers)}', fontsize=16) # Clarify benchmark\n",
    "        plt.title(f'HMM Strategy Performance vs {benchmark_ticker_symbol} - {joined_tickers_str}', fontsize=16) # Clarify benchmark\n",
    "        \n",
    "        plt.xlabel('Date', fontsize=12)\n",
    "        plt.ylabel('Cumulative Returns', fontsize=12)\n",
    "        plt.grid(True, linestyle='--', alpha=0.6)\n",
    "        plt.legend(fontsize=10)\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(CONFIG['PERFORMANCE_PLOT_FILE'])\n",
    "        plt.close()\n",
    "        logging.info(f\"Performance plot saved to {CONFIG['PERFORMANCE_PLOT_FILE']}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Failed to generate performance plot: {e}\")\n",
    "        send_alert(\"ERROR: Plot Generation Failure\", f\"Failed to save performance plot. Error: {e}\")\n",
    "\n",
    "    logging.info(\"HMM trading strategy execution finished.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c071b2cd-f7ee-40b1-931e-fdabf8b3d70a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:finance_env]",
   "language": "python",
   "name": "conda-env-finance_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
